# Application Specification Template
# Copy this template and customize for your application

name: "your-app"
display_name: "Your Application Name"
version: "0.1.0-alpha"
platform_version: ">=1.0.0-dev"

metadata:
  description: "Brief description of your application"
  homepage: "https://your-app.org"
  documentation: "https://your-app.readthedocs.io"
  repository: "https://github.com/your-org/your-app"
  license: "MIT"  # or GPL, BSD, Commercial, etc.
  maintainers:
    - name: "Your Name"
      email: "you@example.com"
  tags:
    - category1
    - category2
    - scientific-computing

# Application variants (if your app has multiple versions/modes)
variants:
  - name: "standard"
    display_name: "Standard Version"
    description: "Standard single-node version"
    type: "single-node"  # or "multi-node"
    parallelism: "openmp"  # or "mpi", "serial", "gpu"
    upstream_version: "1.0.0"  # Version of upstream software

# Compute architecture support
# Include only the architectures your application supports
compute:
  architectures:
    # AMD processors
    - name: "c7a"
      family: "amd"
      generation: "zen4"
      instance_types: ["c7a.xlarge", "c7a.2xlarge", "c7a.4xlarge"]
      compiler_flags:
        - "-march=znver4"
        - "-mavx512f"
        - "-O3"
        - "-fopenmp"  # If using OpenMP
      math_library:
        name: "amd-aocl"
        version: "4.2"
        blas: "amdblis@4.2"
        lapack: "amdlibflame@4.2"
      base_image: "hpc-base-amd-zen4:latest"

    - name: "c6a"
      family: "amd"
      generation: "zen3"
      instance_types: ["c6a.xlarge", "c6a.2xlarge"]
      compiler_flags: ["-march=znver3", "-mavx2", "-O3", "-fopenmp"]
      math_library:
        name: "amd-aocl"
        version: "4.2"
      base_image: "hpc-base-amd-zen3:latest"

    # Intel processors
    - name: "c7i"
      family: "intel"
      generation: "sapphire-rapids"
      instance_types: ["c7i.xlarge", "c7i.2xlarge"]
      compiler_flags: ["-march=sapphirerapids", "-mavx512f", "-O3", "-fopenmp"]
      math_library:
        name: "intel-mkl"
        version: "2024.2.0"
      base_image: "hpc-base-intel-spr:latest"

    # ARM processors
    - name: "graviton4"
      family: "arm"
      generation: "neoverse-v2"
      instance_types: ["c8g.xlarge", "c8g.2xlarge"]
      compiler_flags: ["-mcpu=neoverse-v2", "-O3", "-fopenmp"]
      math_library:
        name: "arm-pl"
        version: "24.04"
      base_image: "hpc-base-arm-graviton4:latest"

  # AWS Batch configuration
  batch:
    min_vcpus: 0
    max_vcpus: 500
    spot_bid_percentage: 100  # 100 = use spot price
    queues:
      - name: "your-app-spot"
        priority: 1
        compute_environments:
          - type: "spot"
            architectures: ["graviton4", "c7a"]
            max_vcpus: 400
      - name: "your-app-ondemand"
        priority: 2
        compute_environments:
          - type: "on-demand"
            architectures: ["c7a"]
            max_vcpus: 100

# Container configuration
containers:
  registry: "ecr"  # or "dockerhub"
  repository: "your-app"
  build_system: "docker-buildx"

  variants:
    standard:
      dockerfile: "containers/Dockerfile.template"
      context: "containers/"
      build_args:
        APP_VERSION: "1.0.0"
        # Add other build arguments as needed

  # Dependencies (will be installed in base image or application layer)
  dependencies:
    - hdf5@1.14.3
    - netcdf-c@4.9.2
    # Add your dependencies here

# Storage requirements
storage:
  input:
    type: "s3"  # or "efs", "fsx-lustre"
    bucket: "your-app-input-data"  # S3 bucket name
    prefix: "datasets/v1"  # Optional prefix

  output:
    type: "s3"
    bucket: "your-app-results"
    lifecycle:  # Optional S3 lifecycle rules
      transition_ia: 30  # Move to Infrequent Access after 30 days
      transition_glacier: 90  # Move to Glacier after 90 days
      expiration: 365  # Delete after 1 year

  scratch:
    type: "ebs"  # Local scratch space
    size_gb: 50
    type: "gp3"
    iops: 3000

  # Optional: For applications needing shared filesystem
  shared:
    type: "efs"  # or "fsx-lustre"
    size_gb: 1000
    throughput_mode: "bursting"  # or "provisioned"

# Environment definitions
# These are pre-configured runtime environments for common use cases
environments:
  - name: "test"
    config: "environments/test.yaml"
    description: "Quick test configuration for validation"

  - name: "production"
    config: "environments/production.yaml"
    description: "Full production runs"

# Cost estimation (optional, for scheduler optimization)
cost:
  estimate_method: "runtime_scaling"
  baseline:
    architecture: "c7a.2xlarge"
    runtime_hours: 1.0
    cost_per_hour: 0.3468
  scaling_factors:
    c6a: 0.95
    graviton4: 0.70

# License management (if needed)
# Uncomment and configure if your application requires licensing
# licensing:
#   type: "none"  # or "flexlm", "rlm", "custom"
#   server: "license.university.edu:27000"
#   feature: "your_app_feature"
#   tokens_per_job: 1

# GPU requirements (if needed)
# Uncomment if your application uses GPUs
# gpu:
#   required: false  # or true
#   types: ["nvidia-a100", "nvidia-h100"]
#   count: 1
#   memory_gb: 40

# Networking requirements (if needed for MPI)
# Uncomment for multi-node MPI applications
# networking:
#   efa: true  # Elastic Fabric Adapter for low-latency MPI
#   placement_group: true  # For cluster placement
